{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Get and visualize word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download GloVe embeddings file\n",
    "\n",
    "Because GloVe is a static embedding model, we download the pre-trained GloVe embeddings rather than training our own. The nice thing is, once we have the embeddings file, we can use it for any future code. Here we'll download the GloVe embeddings file from Stanford's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data directory\n",
    "from pathlib import Path\n",
    "\n",
    "local_data_path = Path().resolve().parent / \"local_data\"\n",
    "assert local_data_path.exists(), \"Data path does not exist\"\n",
    "\n",
    "# Download GloVe embeddings to the data directory\n",
    "import requests\n",
    "\n",
    "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "glove_zip_path = local_data_path / \"glove.6B.zip\"\n",
    "if not glove_zip_path.exists():\n",
    "    print(\"Downloading GloVe embeddings... This may take a while.\")\n",
    "    response = requests.get(glove_url)\n",
    "    response.raise_for_status()\n",
    "    with open(glove_zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"GloVe embeddings already downloaded.\")\n",
    "\n",
    "# unzip the file\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(glove_zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(local_data_path)\n",
    "print(\"Unzipped GloVe embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. We have the embedding files, let's take a look at what we downloaded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_files = local_data_path.glob(\"*glove*\")\n",
    "for file in glove_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a file called `glove.6B.zip`. This is a zip file containing the GloVe embeddings. You should also see a bunch of files with the format `glove.6B.___d.txt`. These are the actual embeddings files. The number in the filename indicates the dimensionality of the embeddings. For example, `glove.6B.50d.txt` contains 50-dimensional embeddings.\n",
    "\n",
    "Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_size = 100\n",
    "\n",
    "if glove_size not in [50, 100, 200, 300]:\n",
    "    raise ValueError(\"Invalid GloVe size. Must be one of [50, 100, 200, 300].\")\n",
    "\n",
    "glove_file = local_data_path / f\"glove.6B.{glove_size}d.txt\"\n",
    "\n",
    "print(\"Loading GloVe embeddings...\\n\")\n",
    "embeddings = {}\n",
    "with open(glove_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = list(map(float, values[1:]))\n",
    "        embeddings[word] = vector\n",
    "print(\"Examining GloVe embeddings...\")\n",
    "print(f\"Number of embedded words: {len(embeddings)}\")\n",
    "print(f\"Number of dimensions: {len(next(iter(embeddings.values())))}\")\n",
    "print(\n",
    "    f\"First five dimensions of embedding for 'business': {embeddings['business'][:5]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go back and change the `glove_size` to some alternative sizes based on the files you downloaded. \n",
    "* Does the number of embedded words change?\n",
    "* Does the number of dimensions change?\n",
    "* Do the embeddings look different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploring the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some other words. Add some words to the `words` list below and see how the embeddings change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"hello\",\n",
    "    \"world\",\n",
    "    \"business\",\n",
    "    \"economy\",\n",
    "    \"finance\",\n",
    "    \"covfefe\",\n",
    "    \"perniciousness\",\n",
    "    \"ice cream\",\n",
    "]\n",
    "for word in words:\n",
    "    if word in embeddings:\n",
    "        print(f\"Embedding for '{word}': {embeddings[word]}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in GloVe embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened with the \n",
    "\n",
    "* made-up word?\n",
    "* rare word? \n",
    "* compound word?\n",
    "\n",
    "What you observe is a limitation of static embedding models based on individual word tokens. If the word is not in the vocabulary that was used to train the embeddings, the model will not have an embedding for that word.\n",
    "\n",
    "So, \n",
    "* When 'covfefe' was tweeted by President Trump in 2017, there was no embedding for it in the GloVe model.\n",
    "* The word 'perniciousness' is a rare word that was not in the vocabulary of the GloVe model.\n",
    "* \"Ice cream\" is a compound word. Both individual words are in the vocabulary, but the model does not have an embedding for the compound word \"ice cream.\" Moreover, the meaning of the compound word is not just the sum of its parts.\n",
    "\n",
    "What are the implications of this?\n",
    "\n",
    "\n",
    "\n",
    "Despite this limitation, every year new words are added to the dictionary. What does this mean for the evolution of language? \n",
    "\n",
    "Moreover, we use compound words all the time. Even though we can break them down into their component parts, the meaning of the compound word is not always the same as the sum of its parts. For example, \"ice cream\" is a compound word, but its meaning is not just the sum of \"ice\" and \"cream.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider some words that we might think to be similar to or very different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"man\", \"boy\", \"male\", \"woman\", \"girl\", \"female\"]\n",
    "for word in words:\n",
    "    if word in embeddings:\n",
    "        print(f\"Embedding for '{word}': {embeddings[word]}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in GloVe embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these embeddings similar to/different from eachother?\n",
    "\n",
    "It's kind of hard to tell, right? With so many dimensions, it's hard to compare the embeddings. However, we can use a package called `gensim` to make comparisons easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(\n",
    "    glove_file, binary=False, no_header=True\n",
    ")\n",
    "\n",
    "# Compare each pair of words\n",
    "from itertools import combinations\n",
    "\n",
    "for word1, word2 in combinations(words, 2):\n",
    "    if word1 in glove_model and word2 in glove_model:\n",
    "        similarity = glove_model.similarity(word1, word2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
    "    else:\n",
    "        print(f\"'{word1}' or '{word2}' not found in GloVe embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the results comport to your expectations of what would happen? \n",
    "\n",
    "Did you expect that \"male\" and \"female\" would be more similar to each other than \"male\" and \"man\"? Why do you think that this happened (Think back to how these embeddings were trained... what was the training objective?)\n",
    "\n",
    "Now let's look also at the words that are most similar to these words rather than comparing them to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar words to each word in the words list\n",
    "from pprint import pprint\n",
    "\n",
    "for word in words:\n",
    "    if word in glove_model:\n",
    "        similar_words = glove_model.most_similar(word, topn=5)\n",
    "        print(f\"Most similar words to '{word}':\")\n",
    "        pprint(similar_words, indent=4)\n",
    "    else:\n",
    "        print(f\"'{word}' not found in GloVe embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's your turn to explore the embeddings! Find a few words that you're interested in and find how similar they are to other words. What are the most similar words to those words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your playground here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how the reading for this week talked about the ability to do vector algebra with word embeddings? Let's try that out!\n",
    "\n",
    "What happens when we take the vector for \"king\" and subtract the vector for \"man\" and add the vector for \"woman\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# King-man+woman\n",
    "print(f\"King {glove_model['king'][:5]}...\")\n",
    "print(f\"- man {glove_model['man'][:5]}...\")\n",
    "print(f\"+ woman {glove_model['woman'][:5]}...\")\n",
    "result = glove_model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
    "print(f\"\\nSolution: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about if we did the same thing for businessman?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Businessman-man+woman\n",
    "print(f\"Businessman {glove_model['businessman'][:5]}...\")\n",
    "print(f\"- man {glove_model['man'][:5]}...\")\n",
    "print(f\"+ woman {glove_model['woman'][:5]}...\")\n",
    "result = glove_model.most_similar(\n",
    "    positive=[\"businessman\", \"woman\"], negative=[\"man\"], topn=1\n",
    ")\n",
    "print(f\"\\nSolution: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it for yourself... Can you find other similar associations?\n",
    "\n",
    "Do they ALL work or does the algebra break down for some word associations?\n",
    "\n",
    "Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your playground here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualizing the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've played around with the embeddings quite a bit, but it's also helpful to visualize them. Let's use a package called `matplotlib` to visualize the embeddings.\n",
    "\n",
    "However, the embeddings are high-dimensional, so we need to reduce the dimensionality before we can visualize them. One way to do this is to use a technique called t-SNE (t-distributed Stochastic Neighbor Embedding). t-SNE is a technique for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_words(wordlist: list):\n",
    "    word_embeddings = np.array(\n",
    "        [embeddings[word] for word in wordlist if word in embeddings]\n",
    "    )\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=24601)\n",
    "    reduced_embeddings = tsne.fit_transform(word_embeddings)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i, word in enumerate(wordlist):\n",
    "        if word in embeddings:\n",
    "            plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1])\n",
    "            plt.annotate(\n",
    "                word,\n",
    "                xy=(reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "                xytext=(5, 2),\n",
    "                textcoords=\"offset points\",\n",
    "            )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "words = [\"man\", \"boy\", \"male\", \"king\", \"woman\", \"girl\", \"female\", \"queen\"]\n",
    "plot_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, with dimensionality reduction, you necessarily lose some information. However, even when we take high-dimensional data and reduce it to 2 dimensions, we can still see some interesting patterns. How do the words we selected cluster together?\n",
    "\n",
    "Let's try a more diverse set of words and see if we can see other patterns. Let's plot some animals and types of art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = [\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"fish\",\n",
    "    \"bird\",\n",
    "    \"elephant\",\n",
    "    \"giraffe\",\n",
    "    \"lion\",\n",
    "    \"tiger\",\n",
    "    \"bear\",\n",
    "    \"zebra\",\n",
    "]\n",
    "types_of_art = [\n",
    "    \"painting\",\n",
    "    \"sculpture\",\n",
    "    \"photography\",\n",
    "    \"drawing\",\n",
    "    \"printmaking\",\n",
    "    \"collage\",\n",
    "    \"mosaic\",\n",
    "    \"graffiti\",\n",
    "]\n",
    "plot_words(animals + types_of_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any interesting patterns?\n",
    "\n",
    "Let's try one more set of words. Let's try some words related to food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = [\n",
    "    \"pizza\",\n",
    "    \"fish\",\n",
    "    \"burger\",\n",
    "    \"salad\",\n",
    "    \"appetizer\",\n",
    "    \"sushi\",\n",
    "    \"cake\",\n",
    "    \"lettuce\",\n",
    "    \"chocolate\",\n",
    "    \"candy\",\n",
    "]\n",
    "plot_words(foods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again... do you see any interesting patterns?\n",
    "\n",
    "Now let's try adding the food words to our animal and art words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_words(foods + animals + types_of_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that 'fish' shows up twice? That's because 'fish' is both an animal and a type of food. It's on both lists. What do you think about the location of 'fish' in the plot?\n",
    "\n",
    "But wait, the meaning of 'fish' in the context of animals is different from the meaning of 'fish' in the context of food. What does this tell you about the embeddings?\n",
    "\n",
    "This is a limitation of the static embedding model. The model does not take into account the context in which the word is used. For example, the word 'bank' can be a verb or a noun, and it can refer to a financial institution or the side of a river. The model does not take into account these different meanings of the word 'bank.' You get one embedding for the word 'bank,' regardless of its context. That embedding might have some information about the different meanings of the word like you likely see here with respect to its positioning relative to the other food and animal words, but it doesn't fully capture the different meanings of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Document Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been looking at the embeddings of individual words, but sometimes you want to get the embeddings of entire documents. One way to do this from word embeddings is to take the average of the embeddings of all the words in the document. This is called a document embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading a few documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "abstracts_txt = Path() / \"data\" / \"abstracts.txt\"\n",
    "assert abstracts_txt.exists(), \"Abstracts file does not exist\"\n",
    "with open(abstracts_txt, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    abstracts = f.readlines()\n",
    "print(f\"Number of abstracts: {len(abstracts)}\")\n",
    "print(f\"First abstract: {textwrap.fill(abstracts[0], width=80)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from last week, we noted that we generally can't work with raw text. We need to clean it first. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> list:\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not (token.is_punct or token.is_stop or token.is_digit or token.is_space)\n",
    "    ]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "spacy_results = [preprocess(abstract) for abstract in abstracts]\n",
    "\n",
    "pprint(spacy_results, compact=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Make sure you understand why we did each of those preprocessing steps before proceeding. For instance, what would have happened if we didn't remove stop words? If we didn't remove punctuation?\n",
    "\n",
    "Now, let's get the embeddings for each of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_abstracts = []\n",
    "for abstract in spacy_results:\n",
    "    abstract_embeddings = []\n",
    "    for word in abstract:\n",
    "        if word in embeddings:\n",
    "            abstract_embeddings.append(embeddings[word])\n",
    "    if abstract_embeddings:\n",
    "        emb_abstracts.append(abstract_embeddings)\n",
    "\n",
    "for idx, abstract in enumerate(emb_abstracts, 1):\n",
    "    print(f\"Number of embeddings in abstract {idx}: {len(abstract)}\")\n",
    "    print(\n",
    "        f\"\\tFirst five dimensions of first embedding in abstract {idx}: {abstract[0][:5]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"\\tFirst five dimensions of second embedding in abstract {idx}: {abstract[1][:5]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"\\tFirst five dimensions of third embedding in abstract {idx}: {abstract[2][:5]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we have all of the words replaced with their individual embeddings. Now we can take the average of the embeddings for each document to get a document embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = []\n",
    "for abstract in emb_abstracts:\n",
    "    if abstract:\n",
    "        avg_embedding = np.mean(abstract, axis=0)\n",
    "        doc_embeddings.append(avg_embedding)\n",
    "\n",
    "print(f\"Number of document embeddings: {len(doc_embeddings)}\")\n",
    "for idx, doc_embedding in enumerate(doc_embeddings, 1):\n",
    "    print(f\"Document embedding {idx}:\\n{doc_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, but we have the same issue as before... the data are so high-dimensional that it's hard to determine how similar they are. Let's compute the cosine similarity between the document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (doc_pair) in enumerate(combinations(range(len(doc_embeddings)), 2), 1):\n",
    "    doc1_idx, doc2_idx = doc_pair\n",
    "    doc1, doc2 = doc_embeddings[doc1_idx], doc_embeddings[doc2_idx]\n",
    "    similarity = np.dot(doc1, doc2) / (np.linalg.norm(doc1) * np.linalg.norm(doc2))\n",
    "    print(\n",
    "        f\"Similarity between document {doc1_idx + 1} and document {doc2_idx + 1}: {similarity:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that similarity formula doesn't look familiar to you, revisit the chapter 6 reading for this week: formula 6.9\n",
    "\n",
    "They're all pretty similar to eachother, right? Why do you think that is?\n",
    "\n",
    "When we use t-SNE to visualize the document embeddings, we can see that there may be some differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce TSNE visualization of the document embeddings\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=24601, max_iter=10000)\n",
    "reduced_embeddings = tsne.fit_transform(np.array(doc_embeddings))\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(doc_embeddings)):\n",
    "    plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1])\n",
    "    plt.annotate(\n",
    "        f\"Doc {i + 1}\",\n",
    "        xy=(reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "        xytext=(5, 2),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 and 23 seem to be closely related. Let's see if they have something in common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Abstract 12\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[11]))\n",
    "print(\"\\nAbstract 23\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um... not fantastic. Let's look at 48 and 50 that also seem pretty close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Abstract 48\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[47]))\n",
    "print(\"\\nAbstract 50\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[49]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, not fantastic. The problem is that documents are much more than the average of their individiual words. The meaning of a document is not just the sum of its parts. Some words mean more than others (for example, why we got rid of stop words). Also, the order of the words matters. For example, \"the cat sat on the mat\" is different from \"the mat sat on the cat.\"\n",
    "\n",
    "Let's try a better approach. Let's use Open AI's embedding model to get the documents' embeddings instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Using Open AI's Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "text = (\n",
    "    \"Did you go to Paula, add $10 to your OpenAI API key, and put your new key \"\n",
    "    \"it in your '.env' file? If not, this isn't going to work...\"\n",
    ")\n",
    "\n",
    "response = openai.embeddings.create(model=\"text-embedding-3-small\", input=text)\n",
    "print(\n",
    "    textwrap.fill(\n",
    "        f'The OpenAI embedding for the text \"{text}\" is {response.data[0].embedding[:10]}...',\n",
    "        width=100,\n",
    "    )\n",
    ")\n",
    "print()\n",
    "print(\n",
    "    textwrap.fill(\n",
    "        f\"The OpenAI embedding for the text \\\"{text}\\\" is {len(response.data[0].embedding)} dimensions.\",\n",
    "        width=100,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot of dimensions. Let's run the abstracts through the Open AI embedding model and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.embeddings.create(model=\"text-embedding-3-small\", input=abstracts)\n",
    "openai_embeddings = [doc.embedding for doc in response.data]\n",
    "print(f\"Number of OpenAI document embeddings: {len(openai_embeddings)}\")\n",
    "for idx, doc_embedding in enumerate(openai_embeddings, 1):\n",
    "    print(f\"Document embedding {idx}:\\n{doc_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we didn't do ANY preprocessing. We just sent the raw text to the model. This is because the OpenAI model is trained to handle raw text. It handles the preprocessing for us. In fact, if we preprocess the text, we might actually invalidate the meaning of the text. \n",
    "\n",
    "For example, punctuation didn't mean much when we were looking at individual words, but it does mean something when we're looking at entire documents. Same with stop-words, when we're trying to capture the meaning of an entire document, we don't want to get rid of \"the\" or \"a\" because they can change the meaning of the words in-context.\n",
    "\n",
    "The OpenAI model is a contextual embeddings model. This means that it takes into account the context in which the word is used. For example, the word 'bank' would have a different embedding depending on whether it was used in the context of a financial institution or the side of a river.\n",
    "\n",
    "Let's revisualize the embeddings using t-SNE and see if the clusters are more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce TSNE visualization of the Open AI document embeddings\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=24601, max_iter=10000)\n",
    "reduced_embeddings = tsne.fit_transform(np.array(openai_embeddings))\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(openai_embeddings)):\n",
    "    plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1])\n",
    "    plt.annotate(\n",
    "        f\"Doc {i + 1}\",\n",
    "        xy=(reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "        xytext=(5, 2),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we can see that the documents are clustering together in a different way. Let's see if the articles closer together are more similar to each other in a more meaningful way.\n",
    "\n",
    "2 and 39 seem to hang together. Let's look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Abstract 2\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[1]))\n",
    "print(\"\\nAbstract 39\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[38]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, both of those seem to be about decision-making. Those make sense to be located nearer together.\n",
    "\n",
    "\n",
    "What about 3 and 22?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Abstract 3\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[2]))\n",
    "print(\"\\nAbstract 22\\n\", \"-\" * 12)\n",
    "print(textwrap.fill(abstracts[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These both seem to be about the CEO from the strategic management literature.\n",
    "\n",
    "Now do some more exploring on your own. What clusters do you see in the above visualization? What do these clusters 'mean' to you when you look at the texts themselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your playground here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document embeddings are a powerful way to capture the meaning of entire documents. They can be used for a variety of tasks, such as document classification, clustering, and information retrieval. But they are more than the sum/average of the individual words (even when you isolate just the 'important' words). The order of the words matters. The context in which the words are used matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
